References:
- Paper: https://arxiv.org/abs/2507.19457?utm_source=chatgpt.com
- Articles: 

Key Messages:
- Precise information in prompts is pretty important
- You have a lot of power by phrasing your task well
- The automation may be biased and for the user it is still a black box whay something worked
- It is underhyped??
- Only few test data can leverage

Prompt Optimization Is Now an Engineering Discipline

“Why did the last prompt fail? Generate improvements from that diagnosis.”

This changes who can compete. Small teams have leverage again, because they don't need the big guns.

 It Suggests Many “Model Improvements” Are Instruction Problems:

 Some gains attributed to:
	•	“Better alignment”
	•	“Better training”
	•	“Better weights”

Are actually:
	•	Better framing
	•	Better constraints
	•	Better meta-instructions

This shifts attention toward:
	•	Task decomposition
	•	Instruction clarity
	•	Explicit reasoning scaffolding

    Article:


# Put the discipline in before you hit enter. The AI won't have your back just yet.

A paper published in July 2025 (GEPA) demonstrates that systematic prompt refinement — without any model retraining or fine-tuning — can outperform reinforcement learning (GRPO) on its evaluated benchmarks. 

The implication: much of the quality gap in AI output may not be a model problem, but a briefing problem.

## What GEPA actually does

To improve your initial prompt, GEPA evolves prompts through structured reflection. It runs a task, analyzes what went wrong, and mutates the instruction. Then it repeats — systematically, not randomly. (You know which one you're leaning towards.)

Buried in that reflection loop are signals like missing constraints or ambiguous requirements. In other words: the system detects that the task was underspecified — much like a first draft of a project spec always has gaps.


## The implication

Today, GEPA's reflection feeds back into better versions of the original prompt. It doesn't go as far as triggering *clarification* with the user (not in scope of GEPA) — but in my opinion the mechanism points in that direction. And we all know from experience that narrowing down a problem is often the biggest lever...

Think about briefing a contractor: "Write me a marketing strategy" — no serious contractor would accept that as a project brief. You'd expect pushback. *Which market? What budget? What timeline?*

AI doesn't necessarily push back. It guesses — and delivers something confidently generic. Imagine a system that detects task gaps and asks the right questions *before* producing anything (and wasting time). Not heuristic follow-ups, but clarifications that measurably improve the result.

The optimization target shifts from "produce a better answer" to "define the task well enough that good output is the default."

## Who should care

If capability gains live at the instruction layer, you don't always need a data science department or the budget for fine-tuning to get more reliable AI output. You need a better process for defining what you actually want. This changes who can compete — and how fast.

#SharpIntent
---

*GEPA paper: [TODO link]*




Here is an example from the paper to make it tangible for you how the prompt instructions are improved. 
Source: GEPA (arXiv:2507.19457) — Seed prompt vs. optimized prompt for the same task

Seed Prompt:
Given the fields question, summary 1, produce the fields query.

GEPA’s Optimized Prompt for Second-Hop of Multi-Hop QA System, GPT-4.1 Mini
You will be given two input fields: question and summary 1. Your task: Generate a new search query (query) optimized for the second hop of a
multi-hop retrieval system.
• The original user question is typically complex and requires information from multiple documents to answer.
• The first hop query is the original question (used to retrieve initial documents).
• Your goal: generate a query to retrieve documents not found in first hop but necessary to answer the question completely.
Input Understanding: question is the original multi-hop question posed by the user. summary 1 is a concise summary of information from a document
retrieved in the first hop, which partially addresses the question.
Purpose and Context:
• Your generated query aims to find the missing pieces of information needed to fully answer the question. . . .
• The query must retrieve relevant documents NOT found in first hop . . . for final answer extraction.
Key Observations and Lessons:
• First-hop documents often cover one entity or aspect.
• Remaining relevant documents often involve connected or higher-level concepts mentioned in summary 1 but not explicitly asked in the original question.
The query should target these missing, but logically linked, documents.
• Avoid merely paraphrasing the original question or restating known facts from summary 1.
• Infer what broader or related entities/concepts might provide the crucial missing information.
• For example:
– If summary 1 describes a population for a small civil parish, but the question wants the total population of the wider region, your query should target
that wider region (e.g., “Madeira archipelago population in 2011”).
– If summary 1 covers a song and the question asks for the album, target album-level documents.
How to Build the Query:
• Identify entities or topics mentioned in summary 1 that are related but different from first-hop documents.
• Reframe the query to explicitly mention these broader or related entities connected to the original question.
• Include relevant key context from the question to maintain specificity, but shift focus to the missing piece.
• The goal is to retrieve documents that link or complement what was retrieved initially.
Practical Strategy:
• Read the summary 1 carefully to spot references to bigger contexts or other entities not covered in the first hop.
• Ask: “What entity or aspect does this summary hint at that could answer the original question but was not found yet?”
• Formulate a precise, focused factual query targeting that entity or concept to retrieve the missing documents.
Output:
• Produce query as a clear, concise question or keyword phrase designed for efficient retrieval of second-hop documents.
• Ensure the query relates logically to the original question while targeting the broader or complementary knowledge identified in summary 1. . . . Do not
include the original question or simply rephrase it. Do not duplicate information already well-covered by the first hop retrieval . . .

